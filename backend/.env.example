# Writer Assistant Backend Configuration
# Copy this file to .env and configure for your environment

# API Settings
DEBUG=True

# LLM Configuration (Optional - required for AI generation features)
# Path to your GGUF model file
# MODEL_PATH=/path/to/your/model.gguf

# LLM Performance Settings
LLM_N_CTX=4096                # Context window size
LLM_N_GPU_LAYERS=-1           # Number of GPU layers (-1 = all, 0 = CPU only)
# LLM_N_THREADS=8             # Leave commented for auto-detection

# LLM Generation Settings
LLM_TEMPERATURE=0.7           # Sampling temperature (0.0-2.0)
LLM_TOP_P=0.95                # Nucleus sampling threshold
LLM_TOP_K=40                  # Top-k sampling parameter
LLM_MAX_TOKENS=2048           # Maximum tokens to generate
LLM_REPEAT_PENALTY=1.1        # Penalty for repeating tokens
LLM_VERBOSE=False             # Enable verbose logging

# Archive Feature Configuration (Optional)
# Set this to enable the story archive search feature
# If not set or commented out, the archive feature will be disabled
# ARCHIVE_DB_PATH=./chroma_db
ARCHIVE_COLLECTION_NAME=story_archive