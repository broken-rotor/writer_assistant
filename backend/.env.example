# Writer Assistant Backend Configuration
# Copy this file to .env and configure for your environment

# API Settings
DEBUG=True

# LLM Configuration (Optional - required for AI generation features)
# Path to your GGUF model file
# MODEL_PATH=/path/to/your/model.gguf

# LLM Performance Settings
LLM_N_CTX=4096                # Context window size
LLM_N_GPU_LAYERS=-1           # Number of GPU layers (-1 = all, 0 = CPU only)
# LLM_N_THREADS=8             # Leave commented for auto-detection

# LLM Generation Settings
LLM_TEMPERATURE=0.7           # Sampling temperature (0.0-2.0)
LLM_TOP_P=0.95                # Nucleus sampling threshold
LLM_TOP_K=40                  # Top-k sampling parameter
LLM_MAX_TOKENS=2048           # Maximum tokens to generate
LLM_REPEAT_PENALTY=1.1        # Penalty for repeating tokens
LLM_VERBOSE=False             # Enable verbose logging

# Archive Feature Configuration (Optional)
# Set this to enable the story archive search feature
# If not set or commented out, the archive feature will be disabled
# ARCHIVE_DB_PATH=./chroma_db
ARCHIVE_COLLECTION_NAME=story_archive

# Context Management Configuration
# Maximum context window size and buffer allocation
CONTEXT_MAX_TOKENS=32000                    # Maximum context window size
CONTEXT_BUFFER_TOKENS=2000                  # Reserved tokens for generation

# Layer Token Allocation Limits (absolute token numbers)
CONTEXT_LAYER_A_TOKENS=2000                # System instructions (1-2k tokens)
CONTEXT_LAYER_B_TOKENS=0                   # Immediate instructions (included in A)
CONTEXT_LAYER_C_TOKENS=13000               # Recent story segment (10-15k tokens)
CONTEXT_LAYER_D_TOKENS=5000                # Character/scene data (2-5k tokens)
CONTEXT_LAYER_E_TOKENS=10000               # Plot/world summary (5-10k tokens)

# Context Management Performance Settings
CONTEXT_SUMMARIZATION_THRESHOLD=25000      # Token threshold for summarization
CONTEXT_ASSEMBLY_TIMEOUT=100               # Max assembly time in milliseconds

# Context Management Feature Toggles
CONTEXT_ENABLE_RAG=true                    # Enable RAG-based retrieval
CONTEXT_ENABLE_MONITORING=true             # Enable context analytics
CONTEXT_ENABLE_CACHING=true                # Enable context result caching

# Context Optimization Settings
CONTEXT_MIN_PRIORITY_THRESHOLD=0.1         # Minimum priority for content inclusion
CONTEXT_OVERFLOW_STRATEGY=reallocate       # Overflow handling (reject, truncate, borrow, reallocate)
CONTEXT_ALLOCATION_MODE=dynamic            # Allocation mode (static, dynamic, adaptive)
